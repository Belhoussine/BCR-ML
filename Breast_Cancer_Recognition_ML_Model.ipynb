{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast Cancer Recognition ML Model.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Belhoussine/Breast-Cancer-Recognition-ML/blob/master/Breast_Cancer_Recognition_ML_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADLA7T0fL0aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUB3x70QXFEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import csv\n",
        "import gc\n",
        "import cv2\n",
        "\n",
        "def read_pgm(filename, byteorder='>'):\n",
        "    \"\"\"Return image data from a raw PGM file as numpy array.\n",
        "\n",
        "    Format specification: http://netpbm.sourceforge.net/doc/pgm.html\n",
        "\n",
        "    \"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        buffer = f.read()\n",
        "    try:\n",
        "        header, width, height, maxval = re.search(\n",
        "            b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
        "    except AttributeError:\n",
        "        raise ValueError(\"Not a raw PGM file: '%s'\" % filename)\n",
        "    return np.frombuffer(buffer,\n",
        "                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n",
        "                            count=int(width)*int(height),\n",
        "                            offset=len(header)\n",
        "                            ).reshape((int(height), int(width)))\n",
        "def read_csv(filename):\n",
        "  metadata=list()\n",
        "  with open(filename) as csvfile:\n",
        "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "    for row in spamreader:\n",
        "      metadata.append(row)\n",
        "  return metadata\n",
        "if __name__ == \"__main__\":\n",
        "  imageSize=512\n",
        "  ''' Helper Map '''\n",
        "  abnormalityToNum= {'NORM': 0, 'CALC': 1, 'CIRC': 2, 'SPIC': 3, 'MISC':4, 'ARCH':5, 'ASYM':6}\n",
        "  numToAbnormality= {0:'NORM', 1:'CALC', 2:'CIRC', 3:'SPIC', 4:'MISC', 5:'ARCH', 6:'ASYM'}\n",
        "\n",
        "  ''' Metadata Pre-processing'''\n",
        "  csvPath=\"/content/drive/My Drive/metadata.csv\"\n",
        "  metadata=read_csv(csvPath)\n",
        "  labels=set()\n",
        "  for data in metadata:\n",
        "    labels.add((data[0],data[2]))\n",
        "  labels=[i[1] for i in sorted(labels)]\n",
        "  train_labels=[abnormalityToNum[i] for i in labels]\n",
        "\n",
        "  ''' Image Pre-processing '''\n",
        "  pgmPath=\"/content/drive/My Drive/MIAS Database/\"\n",
        "  pgmNames= sorted(os.listdir(pgmPath))\n",
        "  images= list()\n",
        "  for pgm in pgmNames:\n",
        "    image=read_pgm(str(pgmPath+pgm))\n",
        "    images.append(cv2.resize(image, (imageSize,imageSize)))\n",
        "  images = np.asarray(images)\n",
        "  train_img = images / 255.0\n",
        "  train_img=train_img.reshape((-1, imageSize, imageSize,1))\n",
        "\n",
        "  print (np.unique(train_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_Meevbf2Msp",
        "colab_type": "code",
        "outputId": "827381b8-d9f7-4c5d-dbe4-fd6f3a737bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "from sklearn.utils import compute_class_weight\n",
        "classWeight = compute_class_weight('balanced', np.unique(train_labels), train_labels) \n",
        "classWeight = dict(enumerate(classWeight))\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(imageSize,imageSize,1)),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dense(256, activation= 'relu'),\n",
        "    keras.layers.Dense(7, activation='softmax')]\n",
        ")\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(lr=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_img, train_labels,epochs=20, class_weight=classWeight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 322 samples\n",
            "Epoch 1/20\n",
            "322/322 [==============================] - 117s 365ms/sample - loss: 2.0573 - acc: 0.1925\n",
            "Epoch 2/20\n",
            "322/322 [==============================] - 113s 350ms/sample - loss: 1.9253 - acc: 0.1646\n",
            "Epoch 3/20\n",
            "322/322 [==============================] - 112s 349ms/sample - loss: 1.8813 - acc: 0.3354\n",
            "Epoch 4/20\n",
            "322/322 [==============================] - 113s 349ms/sample - loss: 1.7984 - acc: 0.2391\n",
            "Epoch 5/20\n",
            "322/322 [==============================] - 110s 342ms/sample - loss: 1.7256 - acc: 0.2888\n",
            "Epoch 6/20\n",
            "322/322 [==============================] - 111s 345ms/sample - loss: 1.6571 - acc: 0.2360\n",
            "Epoch 7/20\n",
            "322/322 [==============================] - 109s 340ms/sample - loss: 1.4991 - acc: 0.3106\n",
            "Epoch 8/20\n",
            "322/322 [==============================] - 109s 340ms/sample - loss: 1.3754 - acc: 0.3758\n",
            "Epoch 9/20\n",
            "322/322 [==============================] - 110s 341ms/sample - loss: 1.2231 - acc: 0.4037\n",
            "Epoch 10/20\n",
            "322/322 [==============================] - 111s 344ms/sample - loss: 1.0977 - acc: 0.5000\n",
            "Epoch 11/20\n",
            "322/322 [==============================] - 110s 342ms/sample - loss: 0.9523 - acc: 0.5000\n",
            "Epoch 12/20\n",
            "322/322 [==============================] - 111s 346ms/sample - loss: 0.9985 - acc: 0.5466\n",
            "Epoch 13/20\n",
            "322/322 [==============================] - 112s 348ms/sample - loss: 0.7170 - acc: 0.5311\n",
            "Epoch 14/20\n",
            "322/322 [==============================] - 111s 343ms/sample - loss: 0.6375 - acc: 0.6335\n",
            "Epoch 15/20\n",
            "322/322 [==============================] - 112s 346ms/sample - loss: 0.5144 - acc: 0.6925\n",
            "Epoch 16/20\n",
            "322/322 [==============================] - 111s 346ms/sample - loss: 0.5115 - acc: 0.7205\n",
            "Epoch 17/20\n",
            "322/322 [==============================] - 110s 343ms/sample - loss: 0.3950 - acc: 0.7671\n",
            "Epoch 18/20\n",
            "322/322 [==============================] - 111s 345ms/sample - loss: 0.3427 - acc: 0.7484\n",
            "Epoch 19/20\n",
            "322/322 [==============================] - 110s 342ms/sample - loss: 0.2720 - acc: 0.8199\n",
            "Epoch 20/20\n",
            "322/322 [==============================] - 110s 343ms/sample - loss: 0.2223 - acc: 0.8292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f93c148dd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-2aCCPO-BAf",
        "colab_type": "code",
        "outputId": "5aea2c61-b920-44a6-9496-cda2d3503725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cnt=0\n",
        "for i in range (321):\n",
        "  prediction= np.argmax(model.predict(np.expand_dims(train_img[i],0)))\n",
        "  if(numToAbnormality[prediction] == numToAbnormality[train_labels[i]]):\n",
        "    cnt+=1\n",
        "print(cnt/322.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8136645962732919\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}